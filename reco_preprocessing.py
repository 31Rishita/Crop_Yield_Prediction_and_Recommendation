import pandas as pd
import numpy as np
import os, pickle
from sklearn.preprocessing import MinMaxScaler, LabelEncoder

def prepare_reco_data(
    csv_path,
    sequence_length=6
):
    print("ğŸ“‚ Loading dataset...")
    df = pd.read_csv(csv_path)

    print("Initial Dataset Shape:", df.shape)

    # -----------------------------
    # Store original stats
    # -----------------------------
    original_rows = df.shape[0]
    original_missing = df.isnull().sum().sum()

    # -----------------------------
    # Cleaning
    # -----------------------------
    print("\nğŸ§¹ Dropping missing values...")
    df = df.dropna()
    print("Shape after dropping NA:", df.shape)

    print("\nğŸ” Filtering for Andhra Pradesh and Telangana...")
    df = df[df["State Name"].isin(["Andhra Pradesh", "Telangana"])]
    print("Shape after state filtering:", df.shape)

    # -----------------------------
    # Sorting
    # -----------------------------
    print("\nğŸ”„ Sorting dataset by State, District, Crop, Year...")
    df = df.sort_values(
        by=["State Name", "Dist Name", "Crop", "Year"]
    )

    # ğŸ¯ Target
    print("\nğŸ¯ Encoding Crop as Target Variable...")
    crop_encoder = LabelEncoder()
    df["crop_encoded"] = crop_encoder.fit_transform(df["Crop"])

    print("Total Unique Crops:", len(crop_encoder.classes_))
    print("Encoded Crop Classes:", list(crop_encoder.classes_))

    feature_cols = [
        "Area_ha",
        "N_req_kg_per_ha",
        "P_req_kg_per_ha",
        "K_req_kg_per_ha",
        "Temperature_C",
        "Humidity_%",
        "pH",
        "Rainfall_mm",
        "Wind_Speed_m_s",
        "Solar_Radiation_MJ_m2_day"
    ]

    print("\nğŸ“ˆ Selected Feature Columns:")
    print(feature_cols)

    X_raw = df[feature_cols].values
    y_raw = df["crop_encoded"].values

    # -----------------------------
    # Feature Scaling
    # -----------------------------
    print("\nâš– Applying MinMax Scaling to Features...")
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X_raw)
    print("Feature Scaling Completed.")

    # -----------------------------
    # Save Artifacts
    # -----------------------------
    print("\nğŸ’¾ Saving Scaler and Crop Encoder...")
    os.makedirs("models/reco", exist_ok=True)
    pickle.dump(scaler, open("models/reco/reco_scaler.pkl", "wb"))
    pickle.dump(crop_encoder, open("models/reco/crop_encoder.pkl", "wb"))
    print("Artifacts Saved Successfully.")

    # ğŸ” Build sequences
    print("\nğŸ” Creating Sequences for Recommendation Model...")
    X_seq, y_seq = [], []

    for i in range(sequence_length, len(X_scaled)):
        X_seq.append(X_scaled[i-sequence_length:i])
        y_seq.append(y_raw[i])

    X_seq = np.array(X_seq)
    y_seq = np.array(y_seq)

    print("Total Sequences Created:", len(X_seq))

    print("\nğŸ“ Final Output Shapes:")
    print("X_seq Shape:", X_seq.shape)
    print("y_seq Shape:", y_seq.shape)
    print("Time Steps:", sequence_length)
    print("Features per Time Step:", len(feature_cols))

    print("\nâœ… Recommendation Data Preparation Completed Successfully!")

    return X_seq, y_seq


# =========================
# MAIN EXECUTION
# =========================

if __name__ == "__main__":

    csv_file_path = r"dataset/Custom_Crops_yield_Historical_Dataset.csv"

    X, y = prepare_reco_data(
        csv_path=csv_file_path,
        sequence_length=6
    )

    print("\nğŸ¯ Returned Values:")
    print("X shape:", X.shape)
    print("y shape:", y.shape)